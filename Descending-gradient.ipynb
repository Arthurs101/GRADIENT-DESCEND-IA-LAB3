{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.3-Perceptrón"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "# CARGA DE CONJUNTO DE DATOS\n",
    "iris = load_iris()\n",
    "X = iris.data[:, :2] \n",
    "y = iris.target\n",
    "\n",
    "# PARA SOLO TENER LAS 2 CLASES\n",
    "filtro = y < 2\n",
    "X, y = X[filtro], y[filtro]\n",
    "\n",
    "# División de datos de entrenamiento y prueba\n",
    "X_entrenamiento, X_prueba, y_entrenamiento, y_prueba = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "class PerceptronModificado(object):\n",
    "    def __init__(self, tasa_de_aprendizaje=0.01, numero_de_iteraciones=50):\n",
    "        self.tasa_de_aprendizaje = tasa_de_aprendizaje\n",
    "        self.numero_de_iteraciones = numero_de_iteraciones\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n_muestras, n_caracteristicas = X.shape\n",
    "        self.pesos = np.zeros(n_caracteristicas + 1)\n",
    "        self.errores_ = []\n",
    "\n",
    "        for _ in range(self.numero_de_iteraciones):\n",
    "            errores = 0\n",
    "            for i in range(n_muestras):\n",
    "                xi = X[i]\n",
    "                objetivo = y[i]\n",
    "                prediccion = self.predict(xi)\n",
    "                error = objetivo - prediccion\n",
    "                self.pesos[1:] += self.tasa_de_aprendizaje * error * xi\n",
    "                self.pesos[0] += self.tasa_de_aprendizaje * error\n",
    "                errores += int(error != 0.0)\n",
    "            self.errores_.append(errores)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        z = np.dot(X, self.pesos[1:]) + self.pesos[0]\n",
    "        return np.where(z >= 0, 1, 0)\n",
    "\n",
    "\n",
    "perceptron = PerceptronModificado(tasa_de_aprendizaje=0.1, numero_de_iteraciones=10)\n",
    "perceptron.fit(X_entrenamiento, y_entrenamiento)\n",
    "\n",
    "# Evaluación de modelo\n",
    "y_pred = perceptron.predict(X_prueba)\n",
    "precision = accuracy_score(y_prueba, y_pred)\n",
    "\n",
    "\n",
    "def visualizar_frontera(X, y, modelo):\n",
    "    markers = ('s', 'x', 'o', '^', 'v')\n",
    "    colors = ('red', 'blue', 'lightgreen', 'gray', 'cyan')\n",
    "    cmap = ListedColormap(colors[:len(np.unique(y))])\n",
    "\n",
    "    x1_min, x1_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    x2_min, x2_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, 0.02),\n",
    "                           np.arange(x2_min, x2_max, 0.02))\n",
    "    Z = modelo.predict(np.array([xx1.ravel(), xx2.ravel()]).T)\n",
    "    Z = Z.reshape(xx1.shape)\n",
    "    plt.contourf(xx1, xx2, Z, alpha=0.4, cmap=cmap)\n",
    "    plt.xlim(xx1.min(), xx1.max())\n",
    "    plt.ylim(xx2.min(), xx2.max())\n",
    "\n",
    "    for idx, cl in enumerate(np.unique(y)):\n",
    "        plt.scatter(x=X[y == cl, 0], y=X[y == cl, 1], alpha=0.8, c=[cmap(idx)], marker=markers[idx], label=cl)\n",
    "\n",
    "# Frontera de decisión\n",
    "plt.figure(figsize=(10, 6))\n",
    "visualizar_frontera(X_prueba, y_prueba, perceptron)\n",
    "plt.xlabel('Longitud del sépalo')\n",
    "plt.ylabel('Ancho del sépalo')\n",
    "plt.title(f'Frontera de Decisión - Perceptrón Modificado (Precisión: {precision*100:.2f}%)')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo alcanzó una precisión del 100% en el conjunto de prueba. Esto significa que el modelo fue capaz de clasificar correctamente todas las muestras de prueba, identificando correctamente si pertenecían a la clase 0 o la clase 1 basándose en la longitud y el ancho del sépalo.Se eligió esta metrica de desempeño debido a la simplicidad del problema y el balanceo de las clases.\n",
    "\n",
    "Este alto nivel de precisión indica  que, para este conjunto de datos particular y las clases seleccionadas, el perceptrón modificado ha aprendido de manera efectiva la frontera de decisión entre las dos clases.\n",
    "\n",
    "El alto rendimiento del perceptrón en la clasificación binaria del dataset de Iris se atribuye a características claras que diferencian las clases, un balance de clases que valida la precisión como métrica, y la simplicidad del problema, lo cual es óptimo para el perceptrón."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejercico 2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, chi2, mutual_info_classif\n",
    "\n",
    "# Cargar el dataset\n",
    "file_path = \"high_diamond_ranked_10min.csv\"  # Reemplaza con la ruta correcta a tu archivo\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Eliminar la columna 'gameId'\n",
    "data = data.drop(columns=['gameId'])\n",
    "\n",
    "# Separar la variable objetivo y las caracteristicas\n",
    "X = data.drop('blueWins', axis=1)\n",
    "y = data['blueWins']\n",
    "\n",
    "# Escalar las caracter�sticas al rango [0, 1]\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Dividir el dataset en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Crear y entrenar el modelo de Regresion Logistica\n",
    "logistic_model = LogisticRegression()\n",
    "logistic_model.fit(X_train, y_train)\n",
    "\n",
    "# Realizar predicciones en el conjunto de prueba\n",
    "y_pred = logistic_model.predict(X_test)\n",
    "\n",
    "# Evaluar el modelo original\n",
    "precision_original = precision_score(y_test, y_pred)\n",
    "print(f\"Original Logistic Regression Model Precision: {precision_original}\")\n",
    "\n",
    "# Definir la m�trica de desempe�o (por ejemplo, precisi�n)\n",
    "performance_metric = precision_score\n",
    "\n",
    "# Definir las t�cnicas de selecci�n de caracter�sticas\n",
    "feature_selection_techniques = [\n",
    "    ('Univariate Selection (ANOVA F-statistic)', SelectKBest(f_classif, k=5)),\n",
    "    ('Chi-squared', SelectKBest(chi2, k=5)),\n",
    "    ('Mutual Information', SelectKBest(mutual_info_classif, k=5))\n",
    "]\n",
    "\n",
    "# Ajustar y evaluar el modelo para cada t�cnica de selecci�n de caracter�sticas\n",
    "for name, selector in feature_selection_techniques:\n",
    "    # Seleccionar caracter�sticas\n",
    "    X_train_selected = selector.fit_transform(X_train, y_train)\n",
    "    X_test_selected = selector.transform(X_test)\n",
    "\n",
    "    # Crear y entrenar el modelo SVM\n",
    "    svm_model = SVC()\n",
    "    svm_model.fit(X_train_selected, y_train)\n",
    "\n",
    "    # Realizar predicciones en el conjunto de prueba\n",
    "    y_pred_svm = svm_model.predict(X_test_selected)\n",
    "\n",
    "    # Evaluar el modelo\n",
    "    performance = performance_metric(y_test, y_pred_svm)\n",
    "\n",
    "    # Imprimir los resultados de la m�trica\n",
    "    print(f\"\\nFeature Selection Technique: {name}\")\n",
    "    print(f\"SVM Model Performance (Precision): {performance}\")\n",
    "    print(f\"Selected Features Indices: {selector.get_support(indices=True)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
